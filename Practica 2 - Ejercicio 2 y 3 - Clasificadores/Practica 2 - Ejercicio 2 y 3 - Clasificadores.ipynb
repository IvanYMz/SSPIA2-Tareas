{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "\n",
        "# Desactivar las advertencias de Sklearn\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "# Cargar los datasets desde los archivos CSV\n",
        "swedish_auto_data = pd.read_csv('AutoInsurSweden.csv')\n",
        "wine_quality_data = pd.read_csv('wine-Quality.csv')\n",
        "pima_diabetes_data = pd.read_csv('pima-indians-diabetes.csv')\n",
        "\n",
        "# Categorizar los valores de Y en Swedish Auto Insurance Dataset\n",
        "quartiles = swedish_auto_data['Y'].quantile([0.25, 0.5, 0.75])\n",
        "low_limit = quartiles.iloc[0]\n",
        "medium_limit = quartiles.iloc[1]\n",
        "high_limit = quartiles.iloc[2]\n",
        "\n",
        "def categorize_y(y):\n",
        "    if y <= low_limit:\n",
        "        return 'bajo'\n",
        "    elif y <= medium_limit:\n",
        "        return 'medio'\n",
        "    else:\n",
        "        return 'alto'\n",
        "\n",
        "swedish_auto_data['Y_category'] = swedish_auto_data['Y'].apply(categorize_y)\n",
        "\n",
        "# Definir una función para implementar clasificadores y calcular métricas de evaluación\n",
        "def evaluate_classifier(X, y, classifier):\n",
        "    # Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Entrenar el clasificador\n",
        "    if classifier == LogisticRegression:\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "    else:\n",
        "        model = classifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Hacer predicciones\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calcular métricas de evaluación\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division='warn')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Imprimir métricas\n",
        "    print(\"\\nMétricas: \", classifier.__name__)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "\n",
        "# Swedish Auto Insurance Dataset\n",
        "print(\"\\nSwedish Auto Insurance Dataset:\")\n",
        "X_swedish = swedish_auto_data[['X']]\n",
        "y_swedish = swedish_auto_data['Y_category']\n",
        "evaluate_classifier(X_swedish, y_swedish, LogisticRegression)\n",
        "evaluate_classifier(X_swedish, y_swedish, KNeighborsClassifier)\n",
        "evaluate_classifier(X_swedish, y_swedish, SVC)\n",
        "evaluate_classifier(X_swedish, y_swedish, GaussianNB)\n",
        "evaluate_classifier(X_swedish, y_swedish, MLPClassifier)\n",
        "\n",
        "# Wine Quality Dataset\n",
        "print(\"\\nWine Quality Dataset:\")\n",
        "X_wine = wine_quality_data.drop('quality', axis=1)\n",
        "y_wine = wine_quality_data['quality']\n",
        "evaluate_classifier(X_wine, y_wine, LogisticRegression)\n",
        "evaluate_classifier(X_wine, y_wine, KNeighborsClassifier)\n",
        "evaluate_classifier(X_wine, y_wine, SVC)\n",
        "evaluate_classifier(X_wine, y_wine, GaussianNB)\n",
        "evaluate_classifier(X_wine, y_wine, MLPClassifier)\n",
        "\n",
        "# Pima Indians Diabetes Dataset\n",
        "print(\"\\nPima Indians Diabetes Dataset:\")\n",
        "X_pima = pima_diabetes_data.drop('Class variable (0 or 1)', axis=1)\n",
        "y_pima = pima_diabetes_data['Class variable (0 or 1)']\n",
        "evaluate_classifier(X_pima, y_pima, LogisticRegression)\n",
        "evaluate_classifier(X_pima, y_pima, KNeighborsClassifier)\n",
        "evaluate_classifier(X_pima, y_pima, SVC)\n",
        "evaluate_classifier(X_pima, y_pima, GaussianNB)\n",
        "evaluate_classifier(X_pima, y_pima, MLPClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6y3zcIPSmya",
        "outputId": "9b9bd91a-fd80-45f7-de40-aeb482f1abe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Swedish Auto Insurance Dataset:\n",
            "\n",
            "Métricas:  LogisticRegression\n",
            "Accuracy: 0.6923076923076923\n",
            "Precision: 0.8653846153846154\n",
            "Recall: 0.6923076923076923\n",
            "F1 Score: 0.7433198380566802\n",
            "\n",
            "Métricas:  KNeighborsClassifier\n",
            "Accuracy: 0.6153846153846154\n",
            "Precision: 0.8615384615384615\n",
            "Recall: 0.6153846153846154\n",
            "F1 Score: 0.6837606837606838\n",
            "\n",
            "Métricas:  SVC\n",
            "Accuracy: 0.6923076923076923\n",
            "Precision: 0.8717948717948718\n",
            "Recall: 0.6923076923076923\n",
            "F1 Score: 0.7510121457489879\n",
            "\n",
            "Métricas:  GaussianNB\n",
            "Accuracy: 0.5384615384615384\n",
            "Precision: 0.8717948717948718\n",
            "Recall: 0.5384615384615384\n",
            "F1 Score: 0.6357466063348416\n",
            "\n",
            "Métricas:  MLPClassifier\n",
            "Accuracy: 0.8461538461538461\n",
            "Precision: 0.7159763313609468\n",
            "Recall: 0.8461538461538461\n",
            "F1 Score: 0.7756410256410255\n",
            "\n",
            "Wine Quality Dataset:\n",
            "\n",
            "Métricas:  LogisticRegression\n",
            "Accuracy: 0.575\n",
            "Precision: 0.5287327241022991\n",
            "Recall: 0.575\n",
            "F1 Score: 0.5405306044850028\n",
            "\n",
            "Métricas:  KNeighborsClassifier\n",
            "Accuracy: 0.45625\n",
            "Precision: 0.4222930372807017\n",
            "Recall: 0.45625\n",
            "F1 Score: 0.4298823811312021\n",
            "\n",
            "Métricas:  SVC\n",
            "Accuracy: 0.509375\n",
            "Precision: 0.5644736842105263\n",
            "Recall: 0.509375\n",
            "F1 Score: 0.4618002156789197\n",
            "\n",
            "Métricas:  GaussianNB\n",
            "Accuracy: 0.55\n",
            "Precision: 0.5423266539440204\n",
            "Recall: 0.55\n",
            "F1 Score: 0.5455353196905617\n",
            "\n",
            "Métricas:  MLPClassifier\n",
            "Accuracy: 0.565625\n",
            "Precision: 0.5434997768537466\n",
            "Recall: 0.565625\n",
            "F1 Score: 0.5268257645968489\n",
            "\n",
            "Pima Indians Diabetes Dataset:\n",
            "\n",
            "Métricas:  LogisticRegression\n",
            "Accuracy: 0.7467532467532467\n",
            "Precision: 0.7501539408866995\n",
            "Recall: 0.7467532467532467\n",
            "F1 Score: 0.7481668773704172\n",
            "\n",
            "Métricas:  KNeighborsClassifier\n",
            "Accuracy: 0.6623376623376623\n",
            "Precision: 0.6712245977185163\n",
            "Recall: 0.6623376623376623\n",
            "F1 Score: 0.6657943349753696\n",
            "\n",
            "Métricas:  SVC\n",
            "Accuracy: 0.7662337662337663\n",
            "Precision: 0.7613360869174822\n",
            "Recall: 0.7662337662337663\n",
            "F1 Score: 0.758600583090379\n",
            "\n",
            "Métricas:  GaussianNB\n",
            "Accuracy: 0.7662337662337663\n",
            "Precision: 0.7706639480056073\n",
            "Recall: 0.7662337662337663\n",
            "F1 Score: 0.7679249670568175\n",
            "\n",
            "Métricas:  MLPClassifier\n",
            "Accuracy: 0.7077922077922078\n",
            "Precision: 0.6966976055959107\n",
            "Recall: 0.7077922077922078\n",
            "F1 Score: 0.6900795057477085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "\n",
        "# Desactivar las advertencias de Sklearn\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "# Clasificadores disponibles en Scikit-learn\n",
        "classifiers = {\n",
        "    \"Regresión Logística\": LogisticRegression,\n",
        "    \"K-Vecinos Cercanos\": KNeighborsClassifier,\n",
        "    \"Máquinas de Vectores de Soporte\": SVC,\n",
        "    \"Naive Bayes\": GaussianNB,\n",
        "    \"Red Neuronal\": MLPClassifier\n",
        "}\n",
        "\n",
        "# Cargar los datasets desde los archivos CSV\n",
        "swedish_auto_data = pd.read_csv('AutoInsurSweden.csv')\n",
        "wine_quality_data = pd.read_csv('wine-Quality.csv')\n",
        "pima_diabetes_data = pd.read_csv('pima-indians-diabetes.csv')\n",
        "\n",
        "# Categorizar los valores de Y en Swedish Auto Insurance Dataset\n",
        "quartiles = swedish_auto_data['Y'].quantile([0.25, 0.5, 0.75])\n",
        "low_limit = quartiles.iloc[0]\n",
        "medium_limit = quartiles.iloc[1]\n",
        "high_limit = quartiles.iloc[2]\n",
        "\n",
        "def categorize_y(y):\n",
        "    if y <= low_limit:\n",
        "        return 'bajo'\n",
        "    elif y <= medium_limit:\n",
        "        return 'medio'\n",
        "    else:\n",
        "        return 'alto'\n",
        "\n",
        "swedish_auto_data['Y_category'] = swedish_auto_data['Y'].apply(categorize_y)\n",
        "\n",
        "# Definir una función para implementar clasificadores y calcular métricas de evaluación\n",
        "def evaluate_classifier(X, y, classifier_name):\n",
        "    # Obtener el clasificador correspondiente al nombre\n",
        "    classifier = classifiers[classifier_name]\n",
        "\n",
        "    # Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Entrenar el clasificador\n",
        "    model = classifier()\n",
        "    if classifier == LogisticRegression:\n",
        "        model = classifier(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Hacer predicciones\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calcular métricas de evaluación\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division='warn')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Imprimir métricas junto con el nombre del método de clasificación\n",
        "    print(\"\\nMétricas para el método de clasificación\", classifier_name, \":\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "\n",
        "# Swedish Auto Insurance Dataset\n",
        "print(\"\\nSwedish Auto Insurance Dataset:\")\n",
        "X_swedish = swedish_auto_data[['X']]\n",
        "y_swedish = swedish_auto_data['Y_category']\n",
        "for classifier_name in classifiers:\n",
        "    evaluate_classifier(X_swedish, y_swedish, classifier_name)\n",
        "\n",
        "# Wine Quality Dataset\n",
        "print(\"\\nWine Quality Dataset:\")\n",
        "X_wine = wine_quality_data.drop('quality', axis=1)\n",
        "y_wine = wine_quality_data['quality']\n",
        "for classifier_name in classifiers:\n",
        "    evaluate_classifier(X_wine, y_wine, classifier_name)\n",
        "\n",
        "# Pima Indians Diabetes Dataset\n",
        "print(\"\\nPima Indians Diabetes Dataset:\")\n",
        "X_pima = pima_diabetes_data.drop('Class variable (0 or 1)', axis=1)\n",
        "y_pima = pima_diabetes_data['Class variable (0 or 1)']\n",
        "for classifier_name in classifiers:\n",
        "    evaluate_classifier(X_pima, y_pima, classifier_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYYdpUVRYRJP",
        "outputId": "a6ba2bb7-2d79-42d4-a95b-f428e532e125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Swedish Auto Insurance Dataset:\n",
            "\n",
            "Métricas para el método de clasificación Regresión Logística :\n",
            "Accuracy: 0.6923076923076923\n",
            "Precision: 0.8653846153846154\n",
            "Recall: 0.6923076923076923\n",
            "F1 Score: 0.7433198380566802\n",
            "\n",
            "Métricas para el método de clasificación K-Vecinos Cercanos :\n",
            "Accuracy: 0.6153846153846154\n",
            "Precision: 0.8615384615384615\n",
            "Recall: 0.6153846153846154\n",
            "F1 Score: 0.6837606837606838\n",
            "\n",
            "Métricas para el método de clasificación Máquinas de Vectores de Soporte :\n",
            "Accuracy: 0.6923076923076923\n",
            "Precision: 0.8717948717948718\n",
            "Recall: 0.6923076923076923\n",
            "F1 Score: 0.7510121457489879\n",
            "\n",
            "Métricas para el método de clasificación Naive Bayes :\n",
            "Accuracy: 0.5384615384615384\n",
            "Precision: 0.8717948717948718\n",
            "Recall: 0.5384615384615384\n",
            "F1 Score: 0.6357466063348416\n",
            "\n",
            "Métricas para el método de clasificación Red Neuronal :\n",
            "Accuracy: 0.8461538461538461\n",
            "Precision: 0.7159763313609468\n",
            "Recall: 0.8461538461538461\n",
            "F1 Score: 0.7756410256410255\n",
            "\n",
            "Wine Quality Dataset:\n",
            "\n",
            "Métricas para el método de clasificación Regresión Logística :\n",
            "Accuracy: 0.575\n",
            "Precision: 0.5287327241022991\n",
            "Recall: 0.575\n",
            "F1 Score: 0.5405306044850028\n",
            "\n",
            "Métricas para el método de clasificación K-Vecinos Cercanos :\n",
            "Accuracy: 0.45625\n",
            "Precision: 0.4222930372807017\n",
            "Recall: 0.45625\n",
            "F1 Score: 0.4298823811312021\n",
            "\n",
            "Métricas para el método de clasificación Máquinas de Vectores de Soporte :\n",
            "Accuracy: 0.509375\n",
            "Precision: 0.5644736842105263\n",
            "Recall: 0.509375\n",
            "F1 Score: 0.4618002156789197\n",
            "\n",
            "Métricas para el método de clasificación Naive Bayes :\n",
            "Accuracy: 0.55\n",
            "Precision: 0.5423266539440204\n",
            "Recall: 0.55\n",
            "F1 Score: 0.5455353196905617\n",
            "\n",
            "Métricas para el método de clasificación Red Neuronal :\n",
            "Accuracy: 0.546875\n",
            "Precision: 0.5149999999999999\n",
            "Recall: 0.546875\n",
            "F1 Score: 0.5183479532163743\n",
            "\n",
            "Pima Indians Diabetes Dataset:\n",
            "\n",
            "Métricas para el método de clasificación Regresión Logística :\n",
            "Accuracy: 0.7467532467532467\n",
            "Precision: 0.7501539408866995\n",
            "Recall: 0.7467532467532467\n",
            "F1 Score: 0.7481668773704172\n",
            "\n",
            "Métricas para el método de clasificación K-Vecinos Cercanos :\n",
            "Accuracy: 0.6623376623376623\n",
            "Precision: 0.6712245977185163\n",
            "Recall: 0.6623376623376623\n",
            "F1 Score: 0.6657943349753696\n",
            "\n",
            "Métricas para el método de clasificación Máquinas de Vectores de Soporte :\n",
            "Accuracy: 0.7662337662337663\n",
            "Precision: 0.7613360869174822\n",
            "Recall: 0.7662337662337663\n",
            "F1 Score: 0.758600583090379\n",
            "\n",
            "Métricas para el método de clasificación Naive Bayes :\n",
            "Accuracy: 0.7662337662337663\n",
            "Precision: 0.7706639480056073\n",
            "Recall: 0.7662337662337663\n",
            "F1 Score: 0.7679249670568175\n",
            "\n",
            "Métricas para el método de clasificación Red Neuronal :\n",
            "Accuracy: 0.7012987012987013\n",
            "Precision: 0.691704433497537\n",
            "Recall: 0.7012987012987013\n",
            "F1 Score: 0.6724064625850339\n"
          ]
        }
      ]
    }
  ]
}